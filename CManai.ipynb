{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CManai",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Aglahir/Beer_Tensorflow/blob/master/CManai.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "57nveqPzOnjO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CMana i"
      ]
    },
    {
      "metadata": {
        "id": "s68R7kCKQgdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aquí va el proyecto"
      ]
    },
    {
      "metadata": {
        "id": "X2CQr-Y7Nnzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8e91924c-5a16-4f35-aada-49d9c585137d"
      },
      "cell_type": "code",
      "source": [
        "#El proposito de este proyecto es entrenar a un máquina utilizando machine learning para lograr la identificación de diferentes marcas de cerveza\n",
        "#en un anaquel\n",
        "#MadeWithLove\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "\n",
        "\n",
        "#¿Por qué las toman en 4K? No se mamen\n",
        "epocas = 20\n",
        "\n",
        "w = 173\n",
        "h = 230\n",
        "\n",
        "pasos = 1000\n",
        "pasosVal = 250 #porque 4 por cada 1000 rifa\n",
        "\n",
        "convUno = 100\n",
        "convDos = 200\n",
        "\n",
        "filUno = (4,4)\n",
        "filDos = (3,3)\n",
        "\n",
        "pools = (2,2)\n",
        "\n",
        "classes = 13\n",
        "\n",
        "fotirris_ent = './fotos/ent'\n",
        "fotirris_tst = './fotos/tst'\n",
        "\n",
        "#Limpia \"Basura\" que haya dejado Keras\n",
        "K.clear_session()\n",
        "\n",
        "#Importa el modelo de aprendizaje\n",
        "keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
        "\n",
        "\n",
        "#Habemus GPU  \n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "print(\"Si ves esto, jala :D\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Si ves esto, jala :D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t4dnrCMyLdIB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bienvenidos a CMana i, a trabajar que las máquinas no aprenden solas. "
      ]
    },
    {
      "metadata": {
        "id": "RgB-nMyVQR6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Tests/Pruebas/Comentarios/Notas/Lo que se les ocurra"
      ]
    },
    {
      "metadata": {
        "id": "vv_EtT1NQFkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d6d6753-1754-4b59-f036-50bb4515cab5"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(\"chequen los atajos de teclado para esto, estan arriba en herramientas\")\n",
        "print(\"Huele a ovo :D\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chequen los atajos de teclado para esto, estan arriba en herramientas\n",
            "Huele a ovo :D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YztsmiAGPbGT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recordatorio amistoso que los capybaras son los roedores más grandes del mundo"
      ]
    },
    {
      "metadata": {
        "id": "fAXAeFbWSfFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Códigos que rolaron los profes"
      ]
    },
    {
      "metadata": {
        "id": "9TDtjRMjSivw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "d39cb720-0593-4cb4-c69f-17005f73f35a"
      },
      "cell_type": "code",
      "source": [
        "#CNN.Py\n",
        "import sys\n",
        "import os\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "\n",
        "\n",
        "data_entrenamiento = './data/entrenamiento'\n",
        "data_validacion = './data/validacion'\n",
        "\n",
        "\"\"\"\n",
        "Parameters\n",
        "\"\"\"\n",
        "epocas=20\n",
        "longitud, altura = 150, 150\n",
        "batch_size = 32\n",
        "pasos = 1000\n",
        "validation_steps = 300\n",
        "filtrosConv1 = 32\n",
        "filtrosConv2 = 64\n",
        "tamano_filtro1 = (3, 3)\n",
        "tamano_filtro2 = (2, 2)\n",
        "tamano_pool = (2, 2)\n",
        "clases = 3\n",
        "lr = 0.0004\n",
        "\n",
        "\n",
        "##Preparamos nuestras imagenes\n",
        "\n",
        "entrenamiento_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(altura, longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validacion_generador = test_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size=(altura, longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(256, activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(clases, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',\n",
        "            optimizer=optimizers.Adam(lr=lr),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cnn.fit_generator(\n",
        "    entrenamiento_generador,\n",
        "    steps_per_epoch=pasos,\n",
        "    epochs=epocas,\n",
        "    validation_data=validacion_generador,\n",
        "    validation_steps=validation_steps)\n",
        "\n",
        "target_dir = './modelo/'\n",
        "if not os.path.exists(target_dir):\n",
        "  os.mkdir(target_dir)\n",
        "cnn.save('./modelo/modelo.h5')\n",
        "cnn.save_weights('./modelo/pesos.h5')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-88a91fc7c519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltura\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     class_mode='categorical')\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m validacion_generador = test_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             interpolation=interpolation)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m   1721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1724\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/entrenamiento'"
          ]
        }
      ]
    }
  ]
}